<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Principal component analysis | Kamal Maher </title> <meta name="author" content="Kamal Maher"> <meta name="description" content="An intuitive derivation of PCA based on graphs"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%AB%A7&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kmaherx.github.io/blog/2025/pca/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kamal</span> Maher </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Principal component analysis</h1> <p class="post-meta"> Created on May 18, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/math"> <i class="fa-solid fa-tag fa-sm"></i> math</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="introduction">Introduction</h3> <p>It’s not a real blog unless I give my take on PCA.</p> <p>There are several other <a href="https://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/" rel="external nofollow noopener" target="_blank">blog posts</a> out there that provide intuition for PCA, but most tend to fall back on the idea of “maximizing variance explained”. This intuition never fully clicked for me. As my <a href="/blog/category/spatial-omics">research turned more toward graphs</a>, I tried to derive PCA from more of a graph perspective, omitting explicit mention of variance altogether. Here, I’ll briefly share the intuition that did end up clicking: it turns out that <strong>variance explained can instead be thought of as the similarity between two graphs</strong>.</p> <h3 id="problem-statement">Problem statement</h3> <p>Consider the data matrix</p> \[\mathbf{X} \in \mathbb{R}^{n \times g},\] <p>where $n$ is the number of observations and $g$ is the number of features. Given my background in single-cell omics, I tend to think of this as a cell-by-gene matrix – hence the odd choice of $g$. In this case, each row corresponds to a measured cell, each column the genes measured across all cells, and each entry the amount that a given gene is expressed in a given cell. (I’ll continue to refer to observations as cells and features as genes just to tie things down to an application.) Viewed as a dimensionality reduction algorithm, the goal of PCA is to reduce “unnecessary” information, thereby emphasizing more prominent patterns in the data. But how do we specify that mathematically?</p> <p>First, we need to explicitly specify <strong>what patterns we’re interested in</strong>. The patterns we will focus on are the relationships between cells (although the relationships between genes would lead to the same result). More specifically, we will consider the pairwise relationships of all cells in terms of their genes. To do this for all pairs of cells, we can calculate the matrix product</p> \[\mathbf{X} \mathbf{X}^{\top} \in \mathbb{R}^{n \times n},\] <p>where each entry describes the similarity between cells $i$ and $j$. Assuming proper mean centering of $\mathbf{X}$, this is simply a covariance matrix. However, in keeping with a graph perspective, we can instead think of this as a network connecting similar cells to one another. It’s not sparse like most adjacency matrices – in fact it’s dense with connections from each cell to all others. But these connections are weighted by similarity, enabling us to intuitively think of $\mathbf{X} \mathbf{X}^{\top}$ as a graph connecting molecularly similar cells.</p> <p>Next, we need to specify <strong>what “reducing information” means</strong>. Let’s think of it as trying to assign each cell a single value (or “metagene”) while trying to maintain the original molecular relationships between cells. Quantitatively, these new values correspond to a vector $\mathbf{v} \in \mathbb{R}^n$. Just as the true molecular relationships between cells were given by $\mathbf{X} \mathbf{X}^{\top} \in \mathbb{R}^{n \times n}$, the graph resulting from our new values is given by</p> \[\mathbf{v} \mathbf{v}^{\top} \in \mathbb{R}^{n \times n}.\] <p>Finally, because we want to maintain the original graph structure as best we can, <strong>we need a way to compare the two graphs</strong>. We’ll do it by summing over the similarities between edge weights in each graph, which are just the individual entries. (To be clear, this entails summing over “similarities between similarities”, which hopefully isn’t too confusing.) This leads us to our final metric for the similarity between our two graphs:</p> \[\lambda = \sum_{ij} (\mathbf{X} \mathbf{X}^{\top})_{ij} (\mathbf{v} \mathbf{v}^{\top})_{ij}.\] <h3 id="solution">Solution</h3> <p>Now we can ask: <strong>how do we maximize this similarity?</strong> It turns out we can solve this just by simplifying the equation. Let $\mathbf{C} = \mathbf{X} \mathbf{X}^{\top}$ represent our original graph of molecular relationships between cells. Then we can rearrange our metric into</p> \[\lambda = \sum_{ij} \mathbf{C}_{ij} v_i v_j.\] <p>This simplifies to the <a href="https://gregorygundersen.com/blog/2022/02/27/positive-definite/" rel="external nofollow noopener" target="_blank">quadratic form</a></p> \[\lambda = \mathbf{v}^{\top} \mathbf{C} \mathbf{v}.\] <p>Now consider that we don’t care about the overall magnitude of $\mathbf{v}$. Rather, we care about its <em>relative</em> differences among the cells. Thus, we should normalize our expression by dividing out the magnitude:</p> \[\lambda = \frac{\mathbf{v}^{\top} \mathbf{C} \mathbf{v}}{\mathbf{v}^{\top} \mathbf{v}}.\] <p>Finally, we can rearrange this equation into an eigenvalue problem:</p> \[\begin{align} &amp; \lambda = {\frac{\mathbf{v}^{\top} \mathbf{C} \mathbf{v}}{\mathbf{v}^{\top} \mathbf{v}}} \nonumber \\ &amp;\rightarrow \lambda \mathbf{v}^{\top} \mathbf{v} = \mathbf{v}^{\top} \mathbf{C} \mathbf{v} \nonumber \\ &amp;\rightarrow \lambda \mathbf{v} = \mathbf{C} \mathbf{v}. \nonumber \end{align}\] <p>Thus, the maximal $\mathbf{v}$ is just the eigenvector associated with the maximal eigenvalue. In PCA, this eigenvector is PC1. The remaining eigenvectors, in order of eigenvalue, are PC2, PC3, etc. The loadings for each PC (i.e. how much each gene contributes to that pattern over the cell graph) can then be calculated by taking the inner product with each gene, i.e. $\mathbf{X}^{\top} \mathbf{v}$.</p> <h3 id="conclusion">Conclusion</h3> <p>This may seem like quite a bit of leg work, but I think it’s worth it for a few reasons. First, it provides a purely geometric and visual derivation of PCA that may be <strong>more intuitive to those who feel comfortable with graphs</strong>. Second, it <strong>makes <a href="https://en.wikipedia.org/wiki/Kosambi%E2%80%93Karhunen%E2%80%93Lo%C3%A8ve_theorem" rel="external nofollow noopener" target="_blank">the connection between PCA and the Fourier transform</a> very clear</strong>, as <a href="https://arxiv.org/abs/2303.12211" rel="external nofollow noopener" target="_blank">eigenvectors of a symmetric matrix are just Fourier modes over the associated graph domain</a>. Thus, you can think of PCs as the lowest-frequency Fourier modes over the molecular similarity graph. (This is literally the same math introduced in my <a href="/blog/2025/graph-fourier">previous post on graph signal processing</a> except that it relies on an adjacency matrix rather than a Laplacian matrix).</p> <p>Hope this is insightful.</p> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Kamal Maher. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>